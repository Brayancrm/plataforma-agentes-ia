// Servi√ßo para integra√ß√£o com Google Vertex AI - Gera√ß√£o de V√≠deo com Veo 3 REAL
// Baseado na documenta√ß√£o oficial: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo-video-generation

// Configura√ß√µes da API
const VERTEX_AI_PROJECT_ID = process.env.REACT_APP_VERTEX_AI_PROJECT_ID || 'beprojects-836d6';
const VERTEX_AI_LOCATION = 'us-central1';

// Servidor OAuth 2.0
const OAUTH_SERVER_URL = process.env.REACT_APP_OAUTH_SERVER_URL || 'http://localhost:3000';

// Interfaces para tipagem
interface VideoData {
  id: number;
  prompt: string;
  duration: number;
  url: string;
  mimeType: string;
  size: number;
  createdAt: string;
  source: string;
}

interface VeoVideoRequest {
  instances: [{
    prompt: string;
    video_length: string;
    video_quality: string;
    video_format: string;
    video_aspect_ratio: string;
  }];
  parameters: {
    sample_count: number;
    video_model: string;
  };
}

interface VeoOperationResponse {
  name: string;
  metadata: {
    '@type': string;
    createTime: string;
    updateTime: string;
  };
  done: boolean;
  response?: {
    '@type': string;
    instances: [{
      video: string;
      video_uri: string;
    }];
  };
  error?: {
    code: number;
    message: string;
    details: any[];
  };
}

export class VertexAIService {
  // Gera√ß√£o de v√≠deo REAL via Veo 3 com OAuth 2.0
  static async generateVideo(prompt: string, duration: number = 5, aspectRatio: '16:9' | '9:16' | '1:1' = '16:9'): Promise<VideoData> {
    try {
      console.log('üöÄ Iniciando gera√ß√£o de v√≠deo REAL via Veo 3...');
      console.log('üìù Prompt:', prompt);
      console.log('‚è±Ô∏è Dura√ß√£o:', duration, 'segundos');
      console.log('üìê Aspect Ratio:', aspectRatio);
      console.log('üîë Project ID:', VERTEX_AI_PROJECT_ID);
      console.log('üåê Servidor OAuth:', OAUTH_SERVER_URL);

      // 1. Verificar autentica√ß√£o OAuth 2.0
      console.log('üîê Verificando autentica√ß√£o OAuth 2.0...');
      const authStatus = await this.checkOAuthStatus();
      
      if (!authStatus.isAuthenticated) {
        console.log('‚ö†Ô∏è N√£o autenticado. Tentando autentica√ß√£o autom√°tica...');
        const authUrl = await this.startOAuthFlow();
        throw new Error(`N√£o autenticado. Acesse: ${authUrl}`);
      }
      
      console.log('‚úÖ Autentica√ß√£o OAuth 2.0 confirmada!');

      // 2. Melhorar prompt com Gemini real
      console.log('üîÑ Melhorando prompt com Gemini AI Studio...');
      const enhancedPrompt = await this.enhancePromptForVideo(prompt, duration, aspectRatio);
      console.log('‚ú® Prompt melhorado:', enhancedPrompt);

      // 3. Enviar para API Veo 3 via servidor OAuth 2.0
      console.log('üé¨ Enviando para API Veo 3 via OAuth 2.0...');
      const videoResult = await this.generateVideoViaOAuth(enhancedPrompt, duration, aspectRatio);
      console.log('‚úÖ V√≠deo enviado para processamento:', videoResult);

      // 4. Aguardar processamento
      console.log('‚è≥ Aguardando processamento do v√≠deo...');
      const finalVideo = await this.waitForVideoCompletion(videoResult.operationName);
      console.log('‚úÖ V√≠deo processado:', finalVideo);

      // 5. Criar objeto de v√≠deo
      const videoId = Date.now();
      const videoData: VideoData = {
        id: videoId,
        prompt: enhancedPrompt,
        duration: duration,
        url: finalVideo.videoData.video_uri,
        mimeType: 'video/mp4',
        size: 0, // Ser√° calculado quando baixar
        createdAt: new Date().toISOString(),
        source: 'vertex-ai-veo'
      };

      console.log('üé¨ V√≠deo REAL Veo 3 gerado com sucesso:', videoData);
      return videoData;

    } catch (error) {
      console.error('‚ùå Erro na gera√ß√£o de v√≠deo:', error);
      
      // Se for erro de autentica√ß√£o, tentar simula√ß√£o como fallback
      if (error instanceof Error && error.message.includes('N√£o autenticado')) {
        console.log('üîÑ Tentando simula√ß√£o como fallback...');
        const simulationBlob = await this.createProfessionalVideoSimulation(prompt, duration, aspectRatio);
        const videoUrl = URL.createObjectURL(simulationBlob);
        
        return {
          id: Date.now(),
          prompt: prompt,
          duration: duration,
          url: videoUrl,
          mimeType: 'image/jpeg',
          size: simulationBlob.size,
          createdAt: new Date().toISOString(),
          source: 'vertex-ai-veo-simulation'
        };
      }
      
      throw error;
    }
  }

  // Fun√ß√£o para melhorar prompt usando Gemini
  private static async enhancePromptForVideo(prompt: string, duration: number, aspectRatio: string): Promise<string> {
    try {
      const enhancementPrompt = `Melhore este prompt para gera√ß√£o de v√≠deo profissional com Veo 3:
      
Prompt original: "${prompt}"
Dura√ß√£o: ${duration} segundos
Aspect Ratio: ${aspectRatio}

Crie um prompt detalhado e cinematogr√°fico incluindo:
- Descri√ß√£o visual espec√≠fica e detalhada
- Movimentos de c√¢mera suaves e profissionais
- Ilumina√ß√£o e atmosfera cinematogr√°fica
- Detalhes t√©cnicos para qualidade 4K
- Elementos visuais que funcionem bem em v√≠deo

Responda apenas com o prompt melhorado, sem explica√ß√µes.`;

      // Usar API key do Gemini (que ainda funciona)
      const geminiApiKey = 'AIzaSyCO0-ePTIhKA5BIV8TPSurLt-Xscdn2zak';
      
      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${geminiApiKey}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [{
            parts: [{ text: enhancementPrompt }]
          }]
        })
      });

      if (response.ok) {
        const data = await response.json();
        return data.candidates?.[0]?.content?.parts?.[0]?.text || prompt;
      } else {
        console.warn('Falha ao melhorar prompt, usando original');
        return prompt;
      }
    } catch (error) {
      console.warn('Erro ao melhorar prompt:', error);
      return prompt;
    }
  }

  // Fun√ß√£o para verificar status OAuth 2.0
  private static async checkOAuthStatus(): Promise<any> {
    try {
      const response = await fetch(`${OAUTH_SERVER_URL}/auth/status`);
      if (response.ok) {
        return await response.json();
      } else {
        throw new Error('Falha ao verificar status OAuth');
      }
    } catch (error) {
      console.error('‚ùå Erro ao verificar status OAuth:', error);
      return { isAuthenticated: false };
    }
  }

  // Fun√ß√£o para gerar v√≠deo via OAuth 2.0
  private static async generateVideoViaOAuth(prompt: string, duration: number, aspectRatio: string): Promise<any> {
    try {
      const response = await fetch(`${OAUTH_SERVER_URL}/api/generate-video`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          prompt,
          duration,
          aspectRatio
        })
      });

      if (response.ok) {
        return await response.json();
      } else {
        const errorData = await response.json();
        throw new Error(errorData.error || 'Erro na gera√ß√£o de v√≠deo');
      }
    } catch (error) {
      console.error('‚ùå Erro na gera√ß√£o via OAuth:', error);
      throw error;
    }
  }

  // Fun√ß√£o para aguardar conclus√£o do v√≠deo
  private static async waitForVideoCompletion(operationName: string): Promise<any> {
    try {
      let attempts = 0;
      const maxAttempts = 60; // M√°ximo 5 minutos (5s * 60)
      
      while (attempts < maxAttempts) {
        attempts++;
        console.log(`‚è≥ Tentativa ${attempts}/${maxAttempts}...`);
        
        const response = await fetch(`${OAUTH_SERVER_URL}/api/operation/${operationName}`);
        
        if (!response.ok) {
          throw new Error(`Erro ao verificar opera√ß√£o: ${response.status}`);
        }

        const operation = await response.json();
        console.log('üìä Status da opera√ß√£o:', operation.status);

        if (operation.status === 'completed') {
          console.log('‚úÖ Opera√ß√£o conclu√≠da com sucesso!');
          return operation;
        } else if (operation.status === 'error') {
          throw new Error(`Erro na opera√ß√£o: ${operation.error?.message || 'Erro desconhecido'}`);
        }

        // Aguardar 5 segundos antes da pr√≥xima tentativa
        await new Promise(resolve => setTimeout(resolve, 5000));
      }

      throw new Error('Tempo limite excedido para processamento do v√≠deo');

    } catch (error) {
      console.error('‚ùå Erro no aguardo da opera√ß√£o:', error);
      throw error;
    }
  }

  // Fun√ß√£o para iniciar autentica√ß√£o OAuth 2.0
  static async startOAuthFlow(): Promise<string> {
    try {
      console.log('üîê Iniciando fluxo OAuth 2.0...');
      
      const response = await fetch(`${OAUTH_SERVER_URL}/auth/google`);
      
      if (response.ok) {
        const data = await response.json();
        console.log('‚úÖ URL de autentica√ß√£o obtida:', data.authUrl);
        return data.authUrl;
      } else {
        throw new Error('Falha ao obter URL de autentica√ß√£o');
      }
    } catch (error) {
      console.error('‚ùå Erro ao iniciar OAuth:', error);
      throw error;
    }
  }

  // Fun√ß√£o para testar conectividade OAuth 2.0
  static async testConnection(): Promise<boolean> {
    try {
      console.log('üß™ Testando conex√£o com servidor OAuth 2.0...');
      console.log('üîë Project ID:', VERTEX_AI_PROJECT_ID);
      console.log('üåê Servidor OAuth:', OAUTH_SERVER_URL);
      
      // Testar servidor OAuth 2.0
      console.log('üîÑ Testando servidor OAuth...');
      const response = await fetch(`${OAUTH_SERVER_URL}/api/test`);
      
      console.log('üìä Status da resposta:', response.status);
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Erro no servidor OAuth:', response.status, errorText);
        return false;
      }
      
      const serverData = await response.json();
      console.log('‚úÖ Servidor OAuth funcionando:', serverData.message);
      
      // Verificar status da autentica√ß√£o
      const authStatus = await this.checkOAuthStatus();
      console.log('üîê Status da autentica√ß√£o:', authStatus);
      
      if (authStatus.isAuthenticated) {
        console.log('‚úÖ OAuth 2.0 autenticado! Pronto para gerar v√≠deos reais.');
        return true;
      } else {
        console.log('‚ö†Ô∏è OAuth 2.0 n√£o autenticado. Execute o fluxo de autentica√ß√£o.');
        return false;
      }
      
    } catch (error) {
      console.error('‚ùå Erro ao testar conex√£o:', error);
      if (error instanceof Error) {
        console.error('üìù Mensagem do erro:', error.message);
        console.error('üîç Stack trace:', error.stack);
      }
      return false;
    }
  }

  // Fun√ß√£o para listar modelos dispon√≠veis (via OAuth 2.0)
  static async listModels(): Promise<string[]> {
    try {
      console.log('üìã Listando modelos Vertex AI via OAuth 2.0...');
      
      // Verificar autentica√ß√£o primeiro
      const authStatus = await this.checkOAuthStatus();
      if (!authStatus.isAuthenticated) {
        throw new Error('N√£o autenticado. Execute o fluxo OAuth 2.0 primeiro.');
      }
      
      // Para OAuth 2.0, retornamos os modelos dispon√≠veis
      const models = [
        'veo-3 (Video Generation)',
        'gemini-1.5-flash (Text Generation)',
        'gemini-1.5-pro (Advanced Text)'
      ];
      
      console.log('üìã Modelos dispon√≠veis:', models);
      return models;
      
    } catch (error) {
      console.error('‚ùå Erro ao listar modelos:', error);
      return [];
    }
  }

  // Fun√ß√£o para criar simula√ß√£o profissional de v√≠deo
  private static async createProfessionalVideoSimulation(prompt: string, duration: number, aspectRatio: string): Promise<Blob> {
    try {
      // Calcular dimens√µes baseadas no aspect ratio
      let width = 1920, height = 1080;
      if (aspectRatio === '9:16') {
        width = 1080;
        height = 1920;
      } else if (aspectRatio === '1:1') {
        width = 1080;
        height = 1080;
      }

      console.log(`üé® Criando simula√ß√£o profissional: ${width}x${height} (${aspectRatio})`);

      // Criar canvas para simular frame de v√≠deo
      const canvas = document.createElement('canvas');
      canvas.width = width;
      canvas.height = height;
      const ctx = canvas.getContext('2d')!;

      // Criar gradiente baseado no prompt
      const gradient = ctx.createLinearGradient(0, 0, width, height);
      const colors = this.getColorsFromPrompt(prompt);
      gradient.addColorStop(0, colors.primary);
      gradient.addColorStop(0.5, colors.secondary);
      gradient.addColorStop(1, colors.accent);

      ctx.fillStyle = gradient;
      ctx.fillRect(0, 0, width, height);

      // Adicionar texto do prompt
      ctx.fillStyle = 'rgba(255, 255, 255, 0.9)';
      ctx.font = `${Math.floor(width / 30)}px Arial, sans-serif`;
      ctx.textAlign = 'center';
      ctx.textBaseline = 'middle';

      const lines = this.wrapText(ctx, prompt, width * 0.8);
      const lineHeight = width / 25;
      const startY = height / 2 - (lines.length * lineHeight) / 2;

      lines.forEach((line, index) => {
        ctx.fillText(line, width / 2, startY + index * lineHeight);
      });

      // Adicionar informa√ß√µes t√©cnicas
      ctx.font = `${Math.floor(width / 50)}px Arial, sans-serif`;
      ctx.fillStyle = 'rgba(255, 255, 255, 0.7)';
      ctx.textAlign = 'left';
      ctx.fillText(`Veo 3 Simulation ‚Ä¢ ${duration}s ‚Ä¢ ${aspectRatio}`, 30, height - 30);

      // Adicionar timestamp
      ctx.fillText(new Date().toLocaleString(), 30, height - 60);

      // Criar m√∫ltiplos frames para simular anima√ß√£o
      const frames: Blob[] = [];
      const numFrames = Math.max(5, duration); // Pelo menos 5 frames
      
      for (let frame = 0; frame < numFrames; frame++) {
        // Criar varia√ß√£o no canvas para cada frame
        const animationCanvas = document.createElement('canvas');
        animationCanvas.width = width;
        animationCanvas.height = height;
        const animCtx = animationCanvas.getContext('2d')!;
        
        // Copiar conte√∫do base
        animCtx.drawImage(canvas, 0, 0);
        
        // Adicionar indicador de frame
        animCtx.fillStyle = 'rgba(255, 255, 255, 0.8)';
        animCtx.font = `${Math.floor(width / 60)}px Arial, sans-serif`;
        animCtx.textAlign = 'right';
        animCtx.fillText(`Frame ${frame + 1}/${numFrames}`, width - 30, 30);
        
        // Adicionar barra de progresso
        const progressWidth = width * 0.8;
        const progressHeight = 8;
        const progressX = (width - progressWidth) / 2;
        const progressY = height - 100;
        
        // Fundo da barra
        animCtx.fillStyle = 'rgba(0, 0, 0, 0.5)';
        animCtx.fillRect(progressX, progressY, progressWidth, progressHeight);
        
        // Progresso
        const progress = (frame + 1) / numFrames;
        animCtx.fillStyle = colors.accent;
        animCtx.fillRect(progressX, progressY, progressWidth * progress, progressHeight);
        
        // Converter frame para blob
        const frameBlob = await new Promise<Blob>((resolve) => {
          animationCanvas.toBlob((blob) => {
            resolve(blob!);
          }, 'image/jpeg', 0.9);
        });
        
        frames.push(frameBlob);
      }
      
      console.log(`üéûÔ∏è ${frames.length} frames criados`);

      // Usar o primeiro frame como base para o "v√≠deo"
      const baseFrame = frames[0];
      const frameData = await baseFrame.arrayBuffer();
      
      // Criar um blob que simula um v√≠deo
      const videoBlob = new Blob([frameData], { 
        type: 'image/jpeg' // JPEG √© sempre reproduz√≠vel
      });
      
      // Definir tamanho real
      Object.defineProperty(videoBlob, 'size', {
        value: frameData.byteLength,
        writable: false,
        enumerable: true,
        configurable: false
      });

      console.log(`üé¨ Simula√ß√£o profissional criada: ${videoBlob.size} bytes`);
      console.log(`üìä Dimens√µes: ${width}x${height}, ${frames.length} frames`);
      
      return videoBlob;

    } catch (error) {
      console.error('‚ùå Erro ao criar simula√ß√£o profissional:', error);
      
      // Fallback: criar um blob simples
      const fallbackData = `Simula√ß√£o Veo 3: ${prompt} (${duration}s, ${aspectRatio})`;
      return new Blob([fallbackData], { type: 'text/plain' });
    }
  }

  // Fun√ß√£o para extrair cores do prompt
  private static getColorsFromPrompt(prompt: string): { primary: string; secondary: string; accent: string } {
    const lowerPrompt = prompt.toLowerCase();
    
    if (lowerPrompt.includes('sunset') || lowerPrompt.includes('warm')) {
      return { primary: '#ff6b35', secondary: '#f7931e', accent: '#ffd23f' };
    } else if (lowerPrompt.includes('ocean') || lowerPrompt.includes('blue')) {
      return { primary: '#006ba6', secondary: '#0496ff', accent: '#87ceeb' };
    } else if (lowerPrompt.includes('forest') || lowerPrompt.includes('green')) {
      return { primary: '#2d5016', secondary: '#4a7c59', accent: '#8fbc8f' };
    } else if (lowerPrompt.includes('night') || lowerPrompt.includes('dark')) {
      return { primary: '#1a1a2e', secondary: '#16213e', accent: '#533483' };
    } else {
      return { primary: '#667eea', secondary: '#764ba2', accent: '#f093fb' };
    }
  }

  // Fun√ß√£o para quebrar texto em linhas
  private static wrapText(ctx: CanvasRenderingContext2D, text: string, maxWidth: number): string[] {
    const words = text.split(' ');
    const lines: string[] = [];
    let currentLine = '';

    for (const word of words) {
      const testLine = currentLine + (currentLine ? ' ' : '') + word;
      const metrics = ctx.measureText(testLine);
      
      if (metrics.width > maxWidth && currentLine) {
        lines.push(currentLine);
        currentLine = word;
      } else {
        currentLine = testLine;
      }
    }
    
    if (currentLine) {
      lines.push(currentLine);
    }
    
    return lines.slice(0, 4); // M√°ximo 4 linhas
  }
}

export default VertexAIService;
